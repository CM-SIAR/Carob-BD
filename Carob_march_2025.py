# -*- coding: utf-8 -*-
"""carob-2-march-2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/CM-SIAR/260340d02e50034f76f8a5614b74fc5f/carob-2-march-2025.ipynb
"""

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2, ResNet50, InceptionV3, EfficientNetB0, DenseNet121
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt

# Mount Google Drive to access the dataset
from google.colab import drive
drive.mount('/content/drive')

# Define paths to the dataset
train_dir = '/content/drive/MyDrive/data/New_Cropped_Balanced_Caroubier_224/Train/'
test_dir = '/content/drive/MyDrive/data/New_Cropped_Balanced_Caroubier_224/Test/'

# Image dimensions and batch size
img_size = (224, 224)
batch_size = 32

# Data augmentation for the training set
train_datagen = ImageDataGenerator(
    rescale=1./255,            # Normalize pixel values to [0, 1]
    rotation_range=20,         # Randomly rotate images by 20 degrees
    width_shift_range=0.2,     # Randomly shift images horizontally by 20%
    height_shift_range=0.2,    # Randomly shift images vertically by 20%
    shear_range=0.2,           # Apply shear transformations
    zoom_range=0.2,            # Randomly zoom images by 20%
    horizontal_flip=True,      # Randomly flip images horizontally
    fill_mode='nearest'        # Fill missing pixels with the nearest value
)

# Only rescale for the test set (no augmentation)
test_datagen = ImageDataGenerator(rescale=1./255)

# Create data generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'  # Binary classification (male/female)
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False  # Do not shuffle for evaluation
)

# Function to build and compile a pretrained model
def build_pretrained_model(base_model, input_shape=(224, 224, 3)):
    # Load the base model
    base_model = base_model(
        input_shape=input_shape,
        include_top=False,  # Exclude the top classification layer
        weights='imagenet'  # Use pretrained weights
    )

    # Freeze the base model layers
    base_model.trainable = False

    # Add custom classification head
    x = base_model.output
    x = GlobalAveragePooling2D()(x)  # Global average pooling layer
    x = Dense(128, activation='relu')(x)  # Fully connected layer
    x = Dropout(0.5)(x)  # Dropout for regularization
    predictions = Dense(1, activation='sigmoid')(x)  # Output layer for binary classification

    # Build the final model
    model = Model(inputs=base_model.input, outputs=predictions)

    # Compile the model
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    return model

# List of pretrained models to test
pretrained_models = [
    MobileNetV2,
    ResNet50,
    InceptionV3,
    EfficientNetB0,
    DenseNet121
]

# Train and evaluate each pretrained model
results = {}
for model_func in pretrained_models:
    print(f"Training and evaluating {model_func.__name__}...")

    # Build the model
    model = build_pretrained_model(model_func)

    # Callbacks
    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    checkpoint = ModelCheckpoint(f'best_{model_func.__name__}.h5', monitor='val_accuracy', save_best_only=True)

    # Train the model
    history = model.fit(
        train_generator,
        steps_per_epoch=train_generator.samples // batch_size,
        validation_data=test_generator,
        validation_steps=test_generator.samples // batch_size,
        epochs=20,
        callbacks=[early_stopping, checkpoint]
    )

    # Evaluate the model
    y_pred = model.predict(test_generator)
    y_pred = np.round(y_pred).flatten()
    y_true = test_generator.classes

    # Store results
    results[model_func.__name__] = {
        'classification_report': classification_report(y_true, y_pred, target_names=['Male', 'Female']),
        'confusion_matrix': confusion_matrix(y_true, y_pred),
        'history': history
    }

# Print results for each model
for model_name, result in results.items():
    print(f"Results for {model_name}:")
    print("Classification Report:")
    print(result['classification_report'])
    print("Confusion Matrix:")
    print(result['confusion_matrix'])
    print("\n")

# Plot training history for each model
def plot_history(history, title):
    plt.figure(figsize=(12, 4))
    plt.suptitle(title)

    # Plot accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()

# Plot history for each model
for model_name, result in results.items():
    plot_history(result['history'], f"{model_name} Training History")